{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1db7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fff9b",
   "metadata": {},
   "source": [
    "## Scrapping Marvel Organisation's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d80c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def team():\n",
    "    individuals = []\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "\n",
    "    action = \"action=query&list=categorymembers\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    limit = \"cmlimit=3000\"  # number of category items returned (max is 500)\n",
    "    dataformat =\"format=json\"\n",
    "    cmtitle = 'cmtitle=Category:Teams'.format()\n",
    "    \n",
    "    q = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content,cmtitle,limit, dataformat)\n",
    "    wikiresponse = urllib.request.urlopen(q)\n",
    "    wikidata = wikiresponse.read()\n",
    "    query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "    for page in query['query']['categorymembers']:\n",
    "        individuals.append(page['title'])\n",
    "\n",
    "        while True: \n",
    "            try:\n",
    "                contin = 'cmcontinue={}'.format(query['continue']['cmcontinue'])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            continue_q = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, content,contin,cmtitle,limit,dataformat)\n",
    "            #print(contin)\n",
    "            wikiresponse = urllib.request.urlopen(continue_q)\n",
    "            wikidata = wikiresponse.read()\n",
    "            query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "            #print(query)\n",
    "            for page in query['query']['categorymembers']:\n",
    "                individuals.append(page['title'])\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7159480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120b0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.DataFrame(teams,columns = ['Name'])\n",
    "df_teams = df_teams.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e971b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"df_team.pickle\", \"wb\")\n",
    "pickle.dump(df_teams, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8f830",
   "metadata": {},
   "source": [
    "## Scrapping text for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d983f1d0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accusers\n",
      "Adrian Toomes' Crew\n",
      "Asgardian Royal Family\n",
      "Avengers\n",
      "Avengers (Fiction)\n",
      "Avengers%Age of Ultron\n",
      "Avengers%Avengers Assassinated\n",
      "Avengers%Zombie Outbreak\n",
      "Barbaria\n",
      "Black Order\n",
      "Black Order%Ravager T'Challa\n",
      "Black Order%Zombie Outbreak\n",
      "Black Widows\n",
      "Centipede Soldiers\n",
      "Cerberus Squad\n",
      "Chronicom Hunters\n",
      "Cleaning Crew\n",
      "Cosmic Beings\n",
      "Coulson's Team\n",
      "Coven\n",
      "Crane Sisters\n",
      "Crick-Hits\n",
      "Criminal Avengers\n",
      "Deathlok Soldiers\n",
      "Defenders\n",
      "Deke Squad\n",
      "Dora Milaje\n",
      "Dora Milaje%Killmonger's War\n",
      "Dora Milaje%Ravager T'Challa\n",
      "EKO Scorpion\n",
      "Eternals\n",
      "Extremis Soldiers\n",
      "Fiona's Crew\n",
      "Garrett's Team\n",
      "Guardians of the Galaxy\n",
      "Guardians of the Galaxy%Age of Ultron\n",
      "Guardians of the Multiverse\n",
      "Howling Commandos\n",
      "Howling Commandos%Super Soldier Peggy Carter\n",
      "Hulkbusters\n",
      "Inhuman Royal Family\n",
      "Invaders\n",
      "Ironette Dancers\n",
      "Izel's Crew\n",
      "Kree Reapers\n",
      "Loki Variant Army\n",
      "Makapu'u Surfers\n",
      "May's Team\n",
      "Minutemen\n",
      "New Warriors\n",
      "Norns\n",
      "P.R.O.T.E.A.N. Hybrids\n",
      "Quentin Beck's Crew\n",
      "Revengers\n",
      "Runaways\n",
      "Runaways%Time-Travelling Runaways\n",
      "Sakaaran Rebellion\n",
      "Sarge's Squad\n",
      "Screamers\n",
      "Scrub Squad\n",
      "Secret Warriors\n",
      "Slicing Talons\n",
      "Sparrows\n",
      "Stakar Ogord's Team\n",
      "Star Spangled Singers\n",
      "Starforce\n",
      "Steeltown Rockers\n",
      "Strategic Operations Command Center\n",
      "STRIKE\n",
      "STRIKE Team: Delta\n",
      "STRIKE%Avengers Assassinated\n",
      "STRIKE%Super Soldier Peggy Carter\n",
      "The Bombers\n",
      "Third Strikers\n",
      "U-Foes\n",
      "United States Navy SEALs\n",
      "United States Navy SEALs%Killmonger's War\n",
      "Valkyries\n",
      "Warriors Three\n",
      "Warriors Three%Avengers Assassinated\n",
      "Warriors Three%Party Prince Thor\n",
      "Winter Soldiers\n",
      "Zealots\n",
      "Zombie Outbreak Survivor Group\n"
     ]
    }
   ],
   "source": [
    "baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "action = \"action=query\"\n",
    "content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "dataformat =\"format=json\"\n",
    "\n",
    "# list of character names - replacing the space with _ such that one can locate the right title\n",
    "team_names = df_teams[\"Name\"]\n",
    "\n",
    "# Looping over every characters name using the same API logic and rexex as above\n",
    "for name in team_names:\n",
    "\n",
    "    title = \"titles=\"+name\n",
    "    link = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\n",
    "    \n",
    "    wikiresponse = requests.get(link)\n",
    "    wikitext = wikiresponse.text\n",
    "    wikijson = json.loads(wikitext)\n",
    "\n",
    "    page_id = list(wikijson[\"query\"][\"pages\"].keys())[0] # The page id for each character\n",
    "    name = name.replace(\"/\", \"%\")\n",
    "    print(name)\n",
    "    \n",
    "    \n",
    "    if len(wikijson[\"query\"][\"pages\"][page_id]['revisions']) > 1:\n",
    "        print(\"Revisions has more than one entry\")\n",
    "    else:\n",
    "        text = wikijson[\"query\"][\"pages\"][page_id]['revisions'][0]['slots']['main']['*']\n",
    "        with open('Teams/'+name+'.txt', 'w', encoding=\"utf-8\") as f: # save the text for each character in the folder\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f5d512",
   "metadata": {},
   "source": [
    "## Create dictionary with raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fb50e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_raw_team_text = {}\n",
    "\n",
    "team_names = df_teams[\"Name\"]\n",
    "\n",
    "for name in team_names:\n",
    "    name = name.replace(\"/\", \"%\")\n",
    "    with open('Teams/'+name+'.txt', 'r',encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        name = name.replace(\"%\",\"/\")\n",
    "        dict_raw_team_text[name] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16cce8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"teams_raw_text.pickle\", \"wb\")\n",
    "pickle.dump(dict_raw_team_text, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c4633",
   "metadata": {},
   "source": [
    "## Extracting all characters within each teams - KÃ˜R HERFRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7528814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_read = open(\"df_team.pickle\", \"rb\")\n",
    "df_team = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "208a0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all teams with Categories or numbers in name\n",
    "remove = []\n",
    "for team in df_team.Name:\n",
    "    if (\"Category\" in team) or (team.isdigit())  :\n",
    "        df_team = df_team[df_team[\"Name\"] != team]\n",
    "        remove.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c124003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_read = open(\"teams_raw_text.pickle\", \"rb\")\n",
    "teams_raw_text = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72726c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"df_characters.pickle\", \"rb\")\n",
    "df_characters = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51a5283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(text, name, df):\n",
    "    \n",
    "    links_all = {}\n",
    "    \n",
    "    #founders\n",
    "    founders = []\n",
    "    founders_text = re.search(r'\\|founder (.*?)\\n', text)\n",
    "    if founders_text:\n",
    "        founders_text = founders_text.group(1)\n",
    "        founders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        founders = re.findall(founders_names, founders_text)\n",
    "        founders = [re.sub(r'\\/.*',\"\",member) for member in founders]\n",
    "        founders = [re.sub(r'.*\\|',\"\",member) for member in founders]\n",
    "    \n",
    "    #leaders\n",
    "    leaders = []\n",
    "    leaders_text = re.search(r'\\|leader (.*?)\\n', text)\n",
    "    if leaders_text:\n",
    "        leaders_text = leaders_text.group(1)\n",
    "        leaders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        leaders = re.findall(leaders_names, leaders_text)\n",
    "        leaders = [re.sub(r'\\/.*',\"\",member) for member in leaders]\n",
    "        leaders = [re.sub(r'.*\\|',\"\",member) for member in leaders]\n",
    "    \n",
    "    #former leaders\n",
    "    formleaders = []\n",
    "    formerleaders_text = re.search(r'\\|formerleaders (.*?)\\n', text)\n",
    "    if formerleaders_text:\n",
    "        formerleaders_text = formerleaders_text.group(1)\n",
    "        formerleaders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        formleaders = re.findall(formerleaders_names, formerleaders_text)\n",
    "        formleaders = [re.sub(r'\\/.*',\"\",member) for member in formleaders]\n",
    "        formleaders = [re.sub(r'.*\\|',\"\",member) for member in formleaders]\n",
    "    \n",
    "    \n",
    "    #members\n",
    "    members = []\n",
    "    members_text = re.search(r'\\|members (.*?)\\n', text)\n",
    "    if members_text:\n",
    "        members_text = members_text.group(1)\n",
    "        members_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        members = re.findall(members_names, members_text)\n",
    "        members = [re.sub(r'\\/.*',\"\",member) for member in members]\n",
    "        members = [re.sub(r'.*\\|',\"\",member) for member in members]\n",
    "    \n",
    "    #former members\n",
    "    formermembers = []\n",
    "    formermembers_text = re.search(r'\\|formermembers (.*?)\\n', text)\n",
    "    if formermembers_text:\n",
    "        formermembers_text = formermembers_text.group(1)\n",
    "        formermembers_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        formermembers = re.findall(formermembers_names, formermembers_text)\n",
    "        formermembers = [re.sub(r'\\/.*',\"\",member) for member in formermembers]\n",
    "        formermembers = [re.sub(r'.*\\|',\"\",member) for member in formermembers]\n",
    "        \n",
    "                                   \n",
    "    links_all = {\"Founders\": founders, \"Leaders\": leaders, \"Former leaders\": formleaders, \n",
    "                       \"Members\": members, \"Former members\": formermembers}\n",
    "    \n",
    "    links_org =[]\n",
    "    links_org.append(founders)\n",
    "    links_org.append(leaders)\n",
    "    links_org.append(formleaders)\n",
    "    links_org.append(members)\n",
    "    links_org.append(formermembers)\n",
    "    links_org = np.unique(links_org)\n",
    "    links_org = [item for sublist in links_org for item in sublist]\n",
    "    \n",
    "    return links_all, links_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a15c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links(dictionary):\n",
    "    links_role = {}\n",
    "    links_all = {}\n",
    "    for keys, values in dictionary.items():\n",
    "        link_role, link_org = get_links(values, keys, df_characters)\n",
    "        links_role[keys] = link_role\n",
    "        links_all[keys] = link_org\n",
    "    return links_role, links_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8e08a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "team_roles, team_all = get_all_links(teams_raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d547ef5",
   "metadata": {},
   "source": [
    "### Gathering teams with more than one name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef3e4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify teams with several names\n",
    "remove = [x for x in df_team['Name'] if (\"/\" in x) or (\"fiction\" in x)]\n",
    "remove.append(\"STRIKE Team: Delta\")\n",
    "remove.append(\"Avengers (Fiction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b58359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather all characters in same team if team have multiple names\n",
    "team_all_new = team_all.copy()\n",
    "for keys, values in team_all.items():\n",
    "    if keys in remove:\n",
    "        if keys == 'Avengers (Fiction)' or keys == 'STRIKE Team: Delta':\n",
    "            input_key = re.sub(r'\\s.*',\"\",keys)\n",
    "        else:\n",
    "            input_key = re.sub(r'\\/.*',\"\",keys)\n",
    "        if input_key in team_all.keys(): #check if org name without / is in dict\n",
    "            for name in values: \n",
    "                if name not in team_all_new[input_key]: #check if name is already in organisation\n",
    "                    team_all_new[input_key].append(name)\n",
    "            team_all_new.pop(keys) #remove old key\n",
    "        else:\n",
    "            team_all_new[input_key] = team_all_new.pop(keys)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d134ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather all characters roles in same team if team have multiple names\n",
    "team_roles_new = team_roles.copy()\n",
    "for keys, values in team_roles.items():\n",
    "    if keys in remove:\n",
    "        \n",
    "        if keys == 'Avengers (Fiction)' or keys == 'STRIKE Team: Delta':\n",
    "            input_key = re.sub(r'\\s.*',\"\",keys)\n",
    "        \n",
    "        else:\n",
    "            input_key = re.sub(r'\\/.*',\"\",keys)\n",
    "\n",
    "        if input_key in team_roles.keys(): #check if org name without / is in dict \n",
    "            for name in team_roles[keys][\"Founders\"]: \n",
    "                if name not in team_roles_new[input_key][\"Founders\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Founders\"].append(name)\n",
    "            \n",
    "            for name in team_roles[keys][\"Leaders\"]: \n",
    "                if name not in team_roles_new[input_key][\"Leaders\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Leaders\"].append(name)\n",
    "                    \n",
    "            for name in team_roles[keys][\"Former leaders\"]: \n",
    "                if name not in team_roles_new[input_key][\"Former leaders\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Former leaders\"].append(name)\n",
    "                    \n",
    "            for name in team_roles[keys][\"Members\"]: \n",
    "                if name not in team_roles_new[input_key][\"Members\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Members\"].append(name)\n",
    "                    \n",
    "            for name in team_roles[keys][\"Former members\"]: \n",
    "                if name not in team_roles_new[input_key][\"Former members\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Former members\"].append(name)\n",
    "              \n",
    "            team_roles_new.pop(keys) #remove old key\n",
    "        else:\n",
    "            team_roles_new[input_key] = team_roles_new.pop(keys)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553df03",
   "metadata": {},
   "source": [
    "### Dictionaries for graph visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "3337e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with characters as keys and team as values\n",
    "dict_team_character = {}\n",
    "for name in df_characters[\"name\"]:\n",
    "    orgs = []\n",
    "    for keys, values in team_all_new.items():\n",
    "        if name in values:\n",
    "            orgs.append(keys)\n",
    "    dict_team_character[name] = orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "3d7d17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with character and links to other characters within same team\n",
    "dict_team_org = {}\n",
    "for keys, values in dict_team_character.items():\n",
    "    characters = []\n",
    "    if values:\n",
    "        for org in values:\n",
    "            for names in team_all_new[org]: \n",
    "                if names != keys: #ensure that we do not create a link to the character itself\n",
    "                    characters.append(names)\n",
    "    dict_team_org[keys] = characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "38474cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with teams and links to other teams if they share characters\n",
    "dict_links_team_name = {}\n",
    "for keys, values in team_all_new.items():\n",
    "    teams = []\n",
    "    count = 0\n",
    "    for i in range(len(team_all_new.keys())):\n",
    "        try:\n",
    "            next_key = list(team_all_new)[list(team_all_new).index(keys) + (i+1)]\n",
    "            for names in values:\n",
    "                if names in team_all_new[next_key]:\n",
    "                    teams.append(next_key)\n",
    "        except (ValueError, IndexError):\n",
    "            count += 1\n",
    "                \n",
    "    dict_links_team_name[keys] = teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "245fa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all teams with no links to other organisations\n",
    "team_links_removed = {k: v for k, v in dict_links_team_name.items() if v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "df667203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing characters that are not part of an organisation\n",
    "team_removed = {k: v for k, v in team_all_new.items() if v}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62a9a6",
   "metadata": {},
   "source": [
    "### Saving dictionaries as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39ad795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"team_shared.pickle\", \"wb\")\n",
    "pickle.dump(team_links_removed, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88110478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"team_characters.pickle\", \"wb\")\n",
    "pickle.dump(team_removed, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aebc0c4",
   "metadata": {},
   "source": [
    "## Graph attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "b3650655",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_character_team = {}\n",
    "\n",
    "for keys1, values1 in dict_team_character.items():\n",
    "    orgs = []\n",
    "    founder = []\n",
    "    leader = []\n",
    "    form_leader = []\n",
    "    member = []\n",
    "    form_member = []\n",
    "    col = []\n",
    "    for keys2, values2 in team_roles_new.items():\n",
    "\n",
    "\n",
    "        teams = values1\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Founders']: #extract founder\n",
    "            founder.append(keys2)\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Leaders']: #extract leader\n",
    "            leader.append(keys2)\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Former leaders']: #extract former leader\n",
    "            form_leader.append(keys2)\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Members']: #extract member\n",
    "            member.append(keys2)\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Former members']: #extract former member\n",
    "            form_member.append(keys2)\n",
    "\n",
    "\n",
    "        col = \"purple\"\n",
    "\n",
    "        attributes_character_team[keys1] = {\"Name\": keys1, \"Team(s)\": teams, \"Founder\": founder, \"Leader\": leader,\n",
    "                                    \"Former leader\": form_leader, \"Member\":member, \"Former member\":form_member,\n",
    "                                    \"Color\": col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "3b16b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def team_att(dictionary):\n",
    "    attributes_team = {}\n",
    "    \n",
    "    from random import randint\n",
    "    colors = []\n",
    "    n = len(dictionary)\n",
    "    for i in range(n):\n",
    "        \n",
    "        colors.append('#%06X' % randint(0, 0xFFFFFF))\n",
    "    n=0\n",
    "    for keys, values in dictionary.items(): \n",
    "        attributes_team[keys] = {\"Name\": keys , \"color\": str(colors[n]), \"shape\": \"diamond\"}\n",
    "        n = n+1\n",
    "    return attributes_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#number of times each organisation is mentioned in another orginasation\n",
    "links_no_team = team_links_removed.copy()\n",
    "for keys, values in team_links_removed.items():\n",
    "    counts = Counter(values)\n",
    "    links_no_team[keys] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfd902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"links_no_team.pickle\", \"wb\")\n",
    "pickle.dump(links_no_team, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "edb131ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def get_edge_att(G):\n",
    "    '''\n",
    "    Function that returns edge attributes\n",
    "    '''\n",
    "    edge_att ={}\n",
    "    for u,v,_ in list(G.edges(data = True)):\n",
    "        \n",
    "        no_links = links_no[u][v]\n",
    "        \n",
    "        edge_att[(u,v)]={'value': no_links, 'title': 'No. of shared characters:' + str(no_links)}\n",
    "    return edge_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f66850",
   "metadata": {},
   "source": [
    "## Converting names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "ea8b084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_characters(dictionary):\n",
    "    removes =[]\n",
    "    for keys, values in dictionary.items():\n",
    "    \n",
    "        #Loki\n",
    "        lokis = ['Loki Variants','Classic Loki','Kid Loki','Boastful Loki','President Loki']\n",
    "        values = ['Loki' if i in lokis else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Thor\n",
    "        thors = ['Bruce Banner','Thor Odinson']\n",
    "        values = ['Thor' if i in thors else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Iron Man\n",
    "        IronMans = ['Tony Stark']\n",
    "        values = ['Iron Man' if i in IronMans else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Captain America\n",
    "        CA = [\"Sam Wilson\"]\n",
    "        values = ['Captain America' if i in CA else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "                \n",
    "        #Black Widow\n",
    "        Black_widows = ['Natasha Romanoff']\n",
    "        values = ['Black Widow' if i in Black_widows else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Hawkeye\n",
    "        Hawkeyes = ['Clint Barton']\n",
    "        values = ['Hawkeye' if i in Hawkeyes else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #War Machine\n",
    "        WarMachines = ['James Rhodes']\n",
    "        values = ['War Machine' if i in WarMachines else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Spyder Man\n",
    "        SpyderMans = ['Peter Parker']\n",
    "        values = ['Spider-Man' if i in SpyderMans else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Scarlet Witch\n",
    "        Wandas = ['Wanda Maximoff']\n",
    "        values = ['Scarlet Witch' if i in Wandas else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Quicksilver \n",
    "        Quicksilver = ['Pietro Maximoff']\n",
    "        values = ['Quicksilver' if i in Quicksilver else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Captain Marvel\n",
    "        CaptainMarvel = ['Carol Danvers']\n",
    "        values = ['Captain Marvel' if i in CaptainMarvel else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Ant-Man\n",
    "        AntMan = ['Scott Lang']\n",
    "        values = ['Ant-Man' if i in AntMan else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "    \n",
    "    lists = [lokis,thors,IronMans,CA,Black_widows,Hawkeyes,WarMachines,SpyderMans,Wandas,Quicksilver,CaptainMarvel,AntMan]\n",
    "    for i in lists:\n",
    "        removes.append(i)\n",
    "    \n",
    "    removes = [item for sublist in removes for item in sublist]\n",
    "    \n",
    "    return dictionary, removes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "137d5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_attributes(attributes_character_team): \n",
    "\n",
    "    #update node attributes \n",
    "    attributes_character_team['Loki']['Team(s)'].append('Loki Variant Army')\n",
    "    attributes_character_team['Loki']['Former leader'].append('Loki Variant Army')\n",
    "    attributes_character_team['Captain America'] = {'Name':'Captain America', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[\"Avengers\"], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Scarlet Witch'] = {'Name':'Scarlet Witch', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Quicksilver'] = {'Name':'Quicksilver', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['War Machine'] = {'Name':'War Machine', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Sam Wilson'] = {'Name':'Sam Wilson', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Spider-Man'] = {'Name':'Spyder-Man', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Captain Marvel'] = {'Name':'Captain Marvel', 'Team(s)':['Avengers','Sparrows'], 'Founder':[], 'Leader':[], 'Former leader':['Sparrows'], 'Member':[\"Avengers\"], 'Former member':['Sparrows'], 'Color':\"purple\"}\n",
    "    attributes_character_team['Ant-Man']['Member'].append('Avengers')\n",
    "    attributes_character_team['Ant-Man']['Team(s)'].append('Avengers')\n",
    "    \n",
    "    return attributes_character_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "b5cc682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_removed,remove_from_att = convert_characters(team_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "0ccc5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_character_all = update_attributes(attributes_character_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "bf2c6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"attributes_character_all.pickle\", \"wb\")\n",
    "pickle.dump(attributes_character_all, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "56842fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_character_team = attributes_character_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "5bcdc222",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'Classic Loki',\n",
       "  'Team(s)': ['Asgardian Royal Family'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': [],\n",
       "  'Member': [],\n",
       "  'Former member': ['Asgardian Royal Family'],\n",
       "  'Color': 'purple'},\n",
       " {'Name': 'Kid Loki',\n",
       "  'Team(s)': ['Asgardian Royal Family'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': [],\n",
       "  'Member': [],\n",
       "  'Former member': ['Asgardian Royal Family'],\n",
       "  'Color': 'purple'},\n",
       " {'Name': 'Boastful Loki',\n",
       "  'Team(s)': ['Asgardian Royal Family'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': [],\n",
       "  'Member': [],\n",
       "  'Former member': ['Asgardian Royal Family'],\n",
       "  'Color': 'purple'},\n",
       " {'Name': 'President Loki',\n",
       "  'Team(s)': ['Asgardian Royal Family', 'Loki Variant Army'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': ['Loki Variant Army'],\n",
       "  'Member': [],\n",
       "  'Former member': ['Asgardian Royal Family'],\n",
       "  'Color': 'purple'},\n",
       " {'Name': 'Sam Wilson',\n",
       "  'Team(s)': ['Avengers'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': [],\n",
       "  'Member': ['Avengers'],\n",
       "  'Former member': [],\n",
       "  'Color': 'purple'}]"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[attributes_character_team.pop(key) for key in remove_from_att if key in attributes_character_team.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "ba1fd5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"attributes_character_team.pickle\", \"wb\")\n",
    "pickle.dump(attributes_character_team, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "d46a414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_team = team_att(team_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e36311",
   "metadata": {},
   "source": [
    "### Interactive graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6dc10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"attributes_character_team.pickle\", \"rb\")\n",
    "attributes_character_team = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f195b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"attributes_team.pickle\", \"rb\")\n",
    "attributes_team = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4a59e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"team_characters.pickle\", \"rb\")\n",
    "team_characters = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcd82eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"team_shared.pickle\", \"rb\")\n",
    "team_shared = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "675ac023",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"links_no_team.pickle\", \"rb\")\n",
    "links_no_team = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c55a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network as net\n",
    "from pyvis.network import Network\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4997984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyvis_graph(G, header, html_title):\n",
    "    character_graph = Network(height='750px', width='90%', \n",
    "                              #bgcolor='#222222',\n",
    "                              heading=header)#, notebook = True)\n",
    "    character_graph.from_nx(G)\n",
    "    character_graph.force_atlas_2based(gravity=-50, central_gravity=0.01, spring_length=50, spring_strength=0.02, damping=0.1, overlap=0)\n",
    "    #character_graph.show_buttons(filter_=['physics'])\n",
    "    return character_graph.show(html_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b39b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(links, dict_attributes):\n",
    "    G = nx.DiGraph(links)\n",
    "    print(\"Number of nodes in total graph: {}\".format(G.number_of_nodes()))\n",
    "    print(\"Number of edges in total graph: {}\".format(G.number_of_edges()))\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    \n",
    "    degrees = dict(G.degree)\n",
    "    nx.set_node_attributes(G, degrees, \"size\")\n",
    "    \n",
    "    nx.set_node_attributes(G,dict_attributes)\n",
    "    \n",
    "    # create giant connected component\n",
    "    GCC = G.subgraph(max(nx.weakly_connected_components(G), key=len)) # the biggest component\n",
    "    print(\"Number of nodes in GCC: {}\".format(GCC.number_of_nodes()))\n",
    "    print(\"Number of edges in GCC: {}\".format(GCC.number_of_edges()))\n",
    "    \n",
    "    return G, GCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142f36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def team_att(dictionary):\n",
    "    attributes_team = {}\n",
    "    \n",
    "    from random import randint\n",
    "    colors = []\n",
    "    n = len(dictionary)\n",
    "    for i in range(n):\n",
    "        \n",
    "        colors.append('#%06X' % randint(0, 0xFFFFFF))\n",
    "    n=0\n",
    "    for keys, values in dictionary.items(): \n",
    "        attributes_team[keys] = {\"Name\": keys , \"color\": str(colors[n]), \"shape\": \"diamond\"}\n",
    "        n = n+1\n",
    "    return attributes_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63af814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_att(G, no_links_dict):\n",
    "    '''\n",
    "    Function that returns edge attributes\n",
    "    '''\n",
    "    edge_att ={}\n",
    "    for u,v,_ in list(G.edges(data = True)):\n",
    "        no_links = no_links_dict[u][v]\n",
    "        edge_att[(u,v)]={'value': no_links, 'title': 'No. of shared characters:' + str(no_links)}\n",
    "    return edge_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0b87e",
   "metadata": {},
   "source": [
    "#### Teams link to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "725aadad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in total graph: 338\n",
      "Number of edges in total graph: 332\n",
      "Number of nodes in GCC: 162\n",
      "Number of edges in GCC: 184\n"
     ]
    }
   ],
   "source": [
    "G_team, GCC_team = create_graph(team_characters,attributes_team)\n",
    "nx.set_node_attributes(G_team, attributes_character_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1181f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {}\n",
    "c = 0\n",
    "for name, data in G_team.nodes(data = True):\n",
    "    if c >= 54:\n",
    "        try:\n",
    "            title = 'Name: '+ name +'</br>Team(s): ' + str(data['Team(s)']) + ' </br>Founder: ' + str(data['Founder']) + ' </br>Leader: ' + str(data['Leader']) + ' </br>Former leader: ' + str(data['Former leader'])+ ' </br>Member: ' + str(data['Member']) + ' </br>Former member: ' + str(data['Former member'])\n",
    "        except:\n",
    "            \"\"\n",
    "    else:\n",
    "        title = 'Team: '+ name +'</br>No. of members: ' + str(data['size'])\n",
    "    titles[name] = title\n",
    "    c = c+1\n",
    "nx.set_node_attributes(G_team, titles, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "14cf3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"Graph_teams.pickle\", \"wb\")\n",
    "pickle.dump(G_team, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e231891",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis_graph(G_team, \"Marvel Teams\", 'team_graph5.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54265b",
   "metadata": {},
   "source": [
    "#### Teams with link to teams org if shared characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66e2b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in total graph: 28\n",
      "Number of edges in total graph: 40\n",
      "Number of nodes in GCC: 24\n",
      "Number of edges in GCC: 38\n"
     ]
    }
   ],
   "source": [
    "G_team_team, GCC_team_team = create_graph(team_shared,team_att(team_shared))\n",
    "nx.set_edge_attributes(G_team_team, get_edge_att(G_team_team, links_no_team))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d497a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {}\n",
    "att = {}\n",
    "for name, data in G_team_team.nodes(data = True):\n",
    "    title = 'Team: '+ name +'</br>No. of shared characters: ' + str(data['size'])\n",
    "    titles[name] = title\n",
    "nx.set_node_attributes(G_team_team, titles, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fbdf763",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = {}\n",
    "for show in G_team_team.nodes():\n",
    "    if show in list(team_shared.keys()):\n",
    "        attribute[show] = {'shape': 'diamond'}\n",
    "    else:\n",
    "        attribute[show] = {'shape': 'diamond', 'color': 'purple'}\n",
    "\n",
    "nx.set_node_attributes(G_team_team, attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "2f800602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"Graph_teams_shared.pickle\", \"wb\")\n",
    "pickle.dump(G_team_team, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60f9d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis_graph(G_team_team, \"Teams With Shared Characters\", 'team_team_graph4.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
