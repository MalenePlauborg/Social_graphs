{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection, cleaning and preprocessing\n",
    "This notebook contains all the steps in our data collection, cleaning and preprocessing described in the explainer notebook. The notebook is divided into different parts. The first parts defines all necessary function applied in order to collect data from fandom. The next part provides and overview of how the dataframes and dictionaries used for the analysis was created using the functions from the previous part. Afterwards it can be seen how the orginal MCU character was created graph using the collected data. \n",
    "In the last two parts the teams network graphs and the organisation network graphs are created and the node and egde attributes are defined.\n",
    "\n",
    "\n",
    "1. [Functions to find all characters, movies, tv-series, teams and organisations](#functions)\n",
    "2. [Apply functions and create dataframes](#dataframes)\n",
    "3. [Create Marvel Cinematic Universe network](#create_MCU_network)\n",
    "    1. [Scraping character pages ](#character_pages)\n",
    "    2. [Extract all character links](#links)\n",
    "    1. [Create links and attributes](#links)\n",
    "    2. [MCU network](#MCU_network)\n",
    "4. [Create team network](#team_network)\n",
    "    1. [Scraping team pages](#team_scraping)\n",
    "    2. [Extract all characters in teams](#Extract_characters)\n",
    "    3. [Dictionaries for visualisation of teams](#dict_for_team_viz)\n",
    "    4. [Attributes for team graph](#graph_attributes)\n",
    "5. [Create organisation network](#organisation_network)\n",
    "    1. [Scraping organisation pages](#org_scraping)\n",
    "    2. [Extracting characters in organisations](#org_extract_characters)\n",
    "    3. [Organisation dictionaries for visualisation](#org_dict_for_viz)\n",
    "    4. [Attributes for organisation graph](#org_graph_attr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to find all characters, movies, tv-series, teams and organisations <a name=\"functions\"></a>\n",
    "Following functions have the same purpose to extract all characters, movies, tv-sereis, teams and organisations from the fandom wiki page. However they are adapted to different urls explaining the different functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character():\n",
    "    '''\n",
    "    This function finds all characters on the marvel universe character page. \n",
    "    \n",
    "    '''\n",
    "    individuals = []\n",
    "    not_in_df = []\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "\n",
    "    action = \"action=query&list=categorymembers\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    limit = \"cmlimit=3000\"  # number of category items returned (max is 500)\n",
    "    dataformat =\"format=json\"\n",
    "    cmtitle = 'cmtitle=Category:Characters'\n",
    "    q = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content,cmtitle,limit, dataformat)\n",
    "    wikiresponse = urllib.request.urlopen(q)\n",
    "    wikidata = wikiresponse.read()\n",
    "    query = json.loads(wikidata.decode('utf-8'))\n",
    "    matches = [\"Category\", \"Captain America/\", \"Captain America (Fiction)\", \"Captain Marvel/\", \n",
    "               \"Iron Man/\",\"Doctor Strange/\", \"Framework\", \"Avengers Assassinated\", \"/Age of Ultron\", \"Decoy\", \n",
    "               \"Chronicom\", \"/Ravager T'Challa\", \"/\", \"(S.H.I.E.L.D.)\", \"(S.S.R.)\", \"(Fiction)\"]\n",
    "    #matches = [\"Category\"]   \n",
    "    for page in query['query']['categorymembers']:\n",
    "        individuals.append(page['title'])\n",
    "\n",
    "        while True: \n",
    "            try:\n",
    "                contin = 'cmcontinue={}'.format(query['continue']['cmcontinue'])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            continue_q = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, content,contin,cmtitle,limit,dataformat)\n",
    "            #print(contin)\n",
    "            wikiresponse = urllib.request.urlopen(continue_q)\n",
    "            wikidata = wikiresponse.read()\n",
    "            query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "            #print(query)\n",
    "            for page in query['query']['categorymembers']:\n",
    "                #print(page['title'])\n",
    "                #if any(x in page['title'] for x in matches):\n",
    "                # This ensures that recurent characters are only mentioned once\n",
    "                # (any(individuals in page['title'] for individuals in individuals)) |  - Fjernede for mange :\n",
    "                if (any(x in page['title'] for x in matches)):\n",
    "                    not_in_df.append(page['title'])\n",
    "                    None\n",
    "                else:\n",
    "                    individuals.append(page['title'])\n",
    "    return individuals, not_in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie(category_name):\n",
    "    '''\n",
    "    This function finds all movies on the marvel universe fandoms movie page\n",
    "    '''\n",
    "    individuals = []\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "\n",
    "    action = \"action=query&list=categorymembers\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    limit = \"cmlimit=3000\"  # number of category items returned (max is 500)\n",
    "    dataformat =\"format=json\"\n",
    "    #cmtitle = 'cmtitle=Category:Characters'.format()\n",
    "    \n",
    "    cmtitle = 'cmtitle=Category:{}'.format(category_name)\n",
    "    #cmtitle = \"\"\n",
    "    \n",
    "    q = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content,cmtitle,limit, dataformat)\n",
    "    wikiresponse = urllib.request.urlopen(q)\n",
    "    wikidata = wikiresponse.read()\n",
    "    query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "    for page in query['query']['categorymembers']:\n",
    "        individuals.append(page['title'])\n",
    "\n",
    "        while True: \n",
    "            try:\n",
    "                contin = 'cmcontinue={}'.format(query['continue']['cmcontinue'])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            continue_q = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, content,contin,cmtitle,limit,dataformat)\n",
    "            #print(contin)\n",
    "            wikiresponse = urllib.request.urlopen(continue_q)\n",
    "            wikidata = wikiresponse.read()\n",
    "            query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "            #print(query)\n",
    "            for page in query['query']['categorymembers']:\n",
    "                individuals.append(page['title'])\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tv():\n",
    "    '''\n",
    "    The function finds all tv-sereies on the fandom page\n",
    "    '''\n",
    "    individuals = []\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "\n",
    "    action = \"action=query&list=categorymembers\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    limit = \"cmlimit=3000\"  # number of category items returned (max is 500)\n",
    "    dataformat =\"format=json\"\n",
    "    #cmtitle = 'cmtitle=Category:Characters'.format()\n",
    "    \n",
    "    cmtitle = 'cmtitle=Category:TV_Series'\n",
    "    #cmtitle = \"\"\n",
    "    \n",
    "    q = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content,cmtitle,limit, dataformat)\n",
    "    wikiresponse = urllib.request.urlopen(q)\n",
    "    wikidata = wikiresponse.read()\n",
    "    query = json.loads(wikidata.decode('utf-8'))\n",
    "    \n",
    "    matches = [\"Category:\"]\n",
    "    \n",
    "    for page in query['query']['categorymembers']:\n",
    "        if (any(x in page['title'] for x in matches)):\n",
    "            None\n",
    "        else:\n",
    "            individuals.append(page['title'])\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team():\n",
    "    '''\n",
    "    This function finds all team on the fandom marvel page\n",
    "    '''\n",
    "    individuals = []\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "\n",
    "    action = \"action=query&list=categorymembers\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    limit = \"cmlimit=3000\"  # number of category items returned (max is 500)\n",
    "    dataformat =\"format=json\"\n",
    "    cmtitle = 'cmtitle=Category:Teams'.format()\n",
    "    \n",
    "    q = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content,cmtitle,limit, dataformat)\n",
    "    wikiresponse = urllib.request.urlopen(q)\n",
    "    wikidata = wikiresponse.read()\n",
    "    query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "    for page in query['query']['categorymembers']:\n",
    "        individuals.append(page['title'])\n",
    "\n",
    "        while True: \n",
    "            try:\n",
    "                contin = 'cmcontinue={}'.format(query['continue']['cmcontinue'])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            continue_q = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, content,contin,cmtitle,limit,dataformat)\n",
    "            #print(contin)\n",
    "            wikiresponse = urllib.request.urlopen(continue_q)\n",
    "            wikidata = wikiresponse.read()\n",
    "            query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "            #print(query)\n",
    "            for page in query['query']['categorymembers']:\n",
    "                individuals.append(page['title'])\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organisation():\n",
    "    '''\n",
    "    This function finds all organisations from the fandom page\n",
    "    '''\n",
    "    individuals = []\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "\n",
    "    action = \"action=query&list=categorymembers\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    limit = \"cmlimit=3000\"  # number of category items returned (max is 500)\n",
    "    dataformat =\"format=json\"\n",
    "    cmtitle = 'cmtitle=Category:Organizations'.format()\n",
    "    \n",
    "    q = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content,cmtitle,limit, dataformat)\n",
    "    wikiresponse = urllib.request.urlopen(q)\n",
    "    wikidata = wikiresponse.read()\n",
    "    query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "    for page in query['query']['categorymembers']:\n",
    "        individuals.append(page['title'])\n",
    "\n",
    "        while True: \n",
    "            try:\n",
    "                contin = 'cmcontinue={}'.format(query['continue']['cmcontinue'])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            continue_q = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, content,contin,cmtitle,limit,dataformat)\n",
    "            wikiresponse = urllib.request.urlopen(continue_q)\n",
    "            wikidata = wikiresponse.read()\n",
    "            query = json.loads(wikidata.decode('utf-8'))\n",
    "\n",
    "            for page in query['query']['categorymembers']:\n",
    "                individuals.append(page['title'])\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframes and dictionaries <a name=\"dataframes\"></a>\n",
    "\n",
    "\n",
    "Following section concatenates the information provided from the different functions into different dataframes and dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the movie dataframe we have defined the phases for the movies when calling the function to extract all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_phase =[\"Phase_One_Movies\", \"Phase_Two_Movies\",\"Phase_Three_Movies\",\"Phase_Four_Movies\"]\n",
    "movie_list = {}\n",
    "for movies in movie_phase:\n",
    "    movie_list[movies] = {'movies': get_movie(movies), 'Phase': movies}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.DataFrame(movie_list.values())\n",
    "df_movies = df_movies.explode('movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create character dataframe. When creating the dataframe it has been necessary to consider change in names in the urls, thus the regex.replace has been applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters, not_in_df = get_character()\n",
    "df_characters = pd.DataFrame(characters, columns = ['name'])\n",
    "df_characters['_name'] = df_characters['name'].replace([\" \",\"\\'\"], [\"_\",\"%27\"], regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tv-series dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = get_tv()\n",
    "df_tv = pd.DataFrame(tv, columns = ['tv_series'])\n",
    "df_tv['_tv_series'] = df_tv['tv_series'].replace([\" \"], [\"_\"], regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create team dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = team()\n",
    "df_teams = pd.DataFrame(teams,columns = ['Name'])\n",
    "df_teams = df_teams.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create organisation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organisations = organisation()\n",
    "df_organisation = pd.DataFrame(organisations,columns = ['Name']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MCU character network <a name=\"create_MCU_network\"></a>\n",
    "\n",
    "The following function are used to create the final MCU character network. It uses the dataframes for tv-series, movies in order to add attributes. Furthermore it uses the function link to create a link between two characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping character page  <a name=\"character_pages\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next section extract the character pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_page(dicts, char_names):\n",
    "    baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "    action = \"action=query\"\n",
    "    content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "    dataformat =\"format=json\"\n",
    "\n",
    "    # Looping over every characters name using the same API logic and rexex as above\n",
    "    for name in char_names:\n",
    "        #print(name)\n",
    "        #name = char_names[idx]\n",
    "        title = \"titles=\"+name\n",
    "        link = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\n",
    "\n",
    "        wikiresponse = requests.get(link)\n",
    "        wikitext = wikiresponse.text\n",
    "        wikijson = json.loads(wikitext)\n",
    "\n",
    "        page_id = list(wikijson[\"query\"][\"pages\"].keys())[0] # The page id for each character\n",
    "\n",
    "        name = name.replace(\"/\", \"%\")\n",
    "\n",
    "        if len(wikijson[\"query\"][\"pages\"][page_id]['revisions']) > 1:\n",
    "            print(\"Revisions has more than one entry\")\n",
    "        else:\n",
    "            text = wikijson[\"query\"][\"pages\"][page_id]['revisions'][0]['slots']['main']['*']\n",
    "            with open(dicts+name+'.txt', 'w') as f: # save the text for each character in the folder\n",
    "                f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of character names - replacing the space with _ such that one can locate the right title\n",
    "char_names = df_characters[\"_name\"]\n",
    "dicts = 'marvel_characters/'\n",
    "\n",
    "get_page(dicts, char_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary with the raw text for characters\n",
    "So we dont have to load every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_raw_text = {}\n",
    "\n",
    "name = df_characters['_name']\n",
    "char_names = df_characters[\"_name\"]\n",
    "\n",
    "for name in char_names:\n",
    "    name = name.replace(\"/\", \"%\")\n",
    "    with open('marvel_characters/'+ name +'.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        name = name.replace(\"%27\",\"\\'\")\n",
    "        name = name.replace(\"%\",\"/\")\n",
    "        name = name.replace(\"_\", \" \")\n",
    "        dict_raw_text[name] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get movie page <a name=\"movie_pages\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace so movie title fits the url title with _\n",
    "df_movies['_movies'] = df_movies['movies'].replace([\" \"], [\"_\"], regex = True)\n",
    "\n",
    "dicts = 'marvel_movies/'\n",
    "char_names =  df_movies[\"_movies\"]\n",
    "get_page(dicts, char_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries with raw text for movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create dictionaries with raw text for movies\n",
    "\n",
    "dict_raw_text_movies = {}\n",
    "\n",
    "for name in movie_names:\n",
    "    with open('marvel_movies/'+ name +'.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        dict_raw_text_movies[name] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store all relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store = open(\"marvel_movies_raw_text.pickle\", \"wb\")\n",
    "pickle.dump(dict_raw_text_movies, file_to_store)\n",
    "file_to_store.close()\n",
    "\n",
    "file_to_store = open(\"marvel_characters_raw_text.pickle\", \"wb\")\n",
    "pickle.dump(dict_raw_text, file_to_store)\n",
    "file_to_store.close()\n",
    "\n",
    "file_to_store = open(\"dict_raw_text_tv_series.pickle\", \"wb\")\n",
    "pickle.dump(dict_raw_text_tv_series, file_to_store)\n",
    "file_to_store.close()\n",
    "\n",
    "file_to_store_df = open(\"df_characters.pickle\", \"wb\")\n",
    "pickle.dump(df_characters, file_to_store_df)\n",
    "file_to_store_df.close()\n",
    "\n",
    "file_to_store_df = open(\"df_movies.pickle\", \"wb\")\n",
    "pickle.dump(df_movies, file_to_store_df)\n",
    "file_to_store_df.close()\n",
    "\n",
    "file_to_store_df = open(\"df_tv.pickle\", \"wb\")\n",
    "pickle.dump(df_tv, file_to_store_df)\n",
    "file_to_store_df.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and attributes links between characters <a name=\"links\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"marvel_movies_raw_text.pickle\", \"rb\")\n",
    "movies_raw_text = pickle.load(file_to_read)\n",
    "file_to_read.close()\n",
    "\n",
    "file_to_read = open(\"marvel_characters_raw_text.pickle\", \"rb\")\n",
    "characters_raw_text = pickle.load(file_to_read)\n",
    "file_to_read.close()\n",
    "\n",
    "file_to_read_characters = open(\"df_characters.pickle\", \"rb\")\n",
    "df_characters = pickle.load(file_to_read_characters)\n",
    "file_to_read_characters.close()\n",
    "\n",
    "file_to_read_movies = open(\"df_movies.pickle\", \"rb\")\n",
    "df_movies = pickle.load(file_to_read_movies)\n",
    "file_to_read_movies.close()\n",
    "\n",
    "file_to_read_movies = open(\"df_tv.pickle\", \"rb\")\n",
    "df_tv = pickle.load(file_to_read_movies)\n",
    "file_to_read_movies.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of movies: 35\n",
      "Number of characters: 3308\n"
     ]
    }
   ],
   "source": [
    "print(\"length of movies: {}\".format(len(df_movies)))\n",
    "print(\"Number of characters: {}\".format(len(df_characters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that searches the characters page to get all attribtues using different regex pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(text, df):\n",
    "    '''\n",
    "    Function that finds all names in the wiki page. \n",
    "    '''\n",
    "    movies = []\n",
    "    tv = []\n",
    "    movie_pattern = r\"(?s)\\[\\[((?:(?!]]).)*)]](?!(?:''|\\))\\s*</?small>)\"\n",
    "    specie_pattern = r'species = \\[\\[(.*?)\\]\\]'\n",
    "    citizenship_pattern = r'citizenship = \\{\\{(.*?)\\}\\}'\n",
    "    status_pattern = r'status = (.*?)\\}\\}'\n",
    "    \n",
    "    tv_pattern = r'\\'\\'\\[\\[(.*?)\\]\\]\\'\\''\n",
    "\n",
    "    #print(text)\n",
    "    #find match \n",
    "    \n",
    "    \n",
    "    match_citezen = re.findall(citizenship_pattern, text)\n",
    "    match_specie = re.findall(specie_pattern, text)\n",
    "    match_status = re.findall(status_pattern, text)\n",
    "    \n",
    "    pattern = r'actor ='\n",
    "    text_movies = re.split(pattern, text, maxsplit=2)[0]\n",
    "    match_movies = re.findall(movie_pattern, text_movies)\n",
    "    \n",
    "    match_tv = re.findall(tv_pattern, text_movies)\n",
    "\n",
    "    for match in match_tv:\n",
    "        match = re.sub(r'\\|.*',\"\",match)\n",
    "        if (match in list(df_tv['tv_series'].values)):\n",
    "            tv.append(match)  \n",
    "    \n",
    "    for match in match_movies:\n",
    "        #print(match)\n",
    "        match = re.sub(r'\\|.*',\"\",match)\n",
    "        #print(match)\n",
    "        if (match in list(df['movies'].values)):\n",
    "            movies.append(match)     \n",
    "    \n",
    "    return list(np.unique(movies)), ' '.join(match_citezen), ' '.join(match_specie) ,  ' '.join(match_status), tv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that gets all links for a character**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(text, name, df):\n",
    "    '''\n",
    "    Function that finds all names in the wiki page. \n",
    "    '''\n",
    "    links = []\n",
    "\n",
    "    pattern = r'\\[\\[(.*?)\\]\\]'\n",
    "    \n",
    "    # find match \n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    for match in matches:\n",
    "        if (match in list(df['name'].values)) & (match != name):\n",
    "            links.append(match)\n",
    "    \n",
    "            \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that defines attributes for the characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_attributes(df_movies, dictionary):\n",
    "    '''\n",
    "    Function that extract all atributes and returns a dictionary. \n",
    "    '''\n",
    "    attributes ={}\n",
    "    # get_attributes(characters_raw_text['Iron Man'], df_movies)\n",
    "    for keys, values in dictionary.items():\n",
    "        #print(keys)\n",
    "        match_movies, match_citezen, match_specie, match_status, match_tv = get_attributes(values, df_movies)\n",
    "        \n",
    "        words = re.findall(r'\\w+',values)\n",
    "        if \"Deceased\" in match_status:\n",
    "            col_status = 'red'\n",
    "        elif  \"Alive\" in match_status:\n",
    "            col_status = 'green'\n",
    "        else:\n",
    "            col_status = 'blue'\n",
    "\n",
    "        attributes[keys] = {'movies': match_movies,'tv-serie':match_tv ,'citizen':match_citezen, \n",
    "                            'specie': match_specie,'status' : match_status,\n",
    "                            'length_of_content': len(words), 'No_movies': len(match_movies), \n",
    "                            'color': col_status}\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get all links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links(df, dictionary):\n",
    "    '''\n",
    "    Funciton that finds the links. \n",
    "    If there are less than 3 links, they will not be considered as an edge.\n",
    "    For the links a dict with the nummber of times a name is mentioned in the text is returned as well. \n",
    "    \n",
    "    '''\n",
    "    links_no = {}\n",
    "    links_no_new = {}\n",
    "    links = {}\n",
    "    for keys, values in dictionary.items():\n",
    "        link = get_links(values, keys, df)\n",
    "        \n",
    "        link_ = {i:link.count(i) for i in link}\n",
    "        links_no[keys] = {k:v for (k,v) in link_.items() if v > 3}\n",
    "        links[keys] = list(links_no[keys].keys())\n",
    "    return links,links_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "links,links_no = get_all_links(df_characters,characters_raw_text)\n",
    "attributes = def_attributes(df_movies, characters_raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function add an edge attribute that defined how many times a character is mentioned on another characters page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_att(G):\n",
    "    '''\n",
    "    Function that returns edge attributes\n",
    "    '''\n",
    "    edge_att ={}\n",
    "    for u,v,_ in list(G.edges(data = True)):\n",
    "        edge_att[(u,v)]={'value': links_no[u][v]}\n",
    "    return edge_att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store_l = open(\"links.pickle\", \"wb\")\n",
    "pickle.dump(links, file_to_store_l)\n",
    "file_to_store_l.close()\n",
    "\n",
    "file_to_store_a = open(\"attributes.pickle\", \"wb\")\n",
    "pickle.dump(attributes, file_to_store_a)\n",
    "file_to_store_a.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCU character network <a name=\"MCU_network\"></a>\n",
    "now we can create the MCU character network applying the functions created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links: 3308\n",
      "attributes: 3308\n"
     ]
    }
   ],
   "source": [
    "print(\"links: {}\".format(len(links))) # check\n",
    "print('attributes: {}'.format(len(attributes.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(links):\n",
    "    G = nx.DiGraph(links)\n",
    "    print(\"Number of nodes in total graph: {}\".format(G.number_of_nodes()))\n",
    "    print(\"Number of edges in total graph: {}\".format(G.number_of_edges()))\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    \n",
    "    # set attributes\n",
    "    nx.set_node_attributes(G,attributes)\n",
    "    \n",
    "    # create giant connected component\n",
    "    GCC = G.subgraph(max(nx.weakly_connected_components(G), key=len)) # the biggest component\n",
    "    print(\"Number of nodes in GCC: {}\".format(GCC.number_of_nodes()))\n",
    "    print(\"Number of edges in GCC: {}\".format(GCC.number_of_edges()))\n",
    "    \n",
    "    return G, GCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, GCC = create_graph(links)\n",
    "\n",
    "edge_att = get_edge_att(G)\n",
    "nx.set_edge_attributes(G, edge_att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE GRAPH For analysis\n",
    "\n",
    "file_to_store = open(\"graph_G.pickle\", \"wb\")\n",
    "pickle.dump(G, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Teams network <a name=\"team_network\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping text for each team <a name=\"team_scraping\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "action = \"action=query\"\n",
    "content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "dataformat =\"format=json\"\n",
    "\n",
    "# list of character names - replacing the space with _ such that one can locate the right title\n",
    "team_names = df_teams[\"Name\"]\n",
    "\n",
    "# Looping over every characters name using the same API logic and rexex as above\n",
    "for name in team_names:\n",
    "    title = \"titles=\"+name\n",
    "    link = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\n",
    "    \n",
    "    wikiresponse = requests.get(link)\n",
    "    wikitext = wikiresponse.text\n",
    "    wikijson = json.loads(wikitext)\n",
    "\n",
    "    page_id = list(wikijson[\"query\"][\"pages\"].keys())[0] # The page id for each character\n",
    "    name = name.replace(\"/\", \"%\")\n",
    "    \n",
    "    if len(wikijson[\"query\"][\"pages\"][page_id]['revisions']) > 1:\n",
    "        print(\"Revisions has more than one entry\")\n",
    "    else:\n",
    "        text = wikijson[\"query\"][\"pages\"][page_id]['revisions'][0]['slots']['main']['*']\n",
    "        with open('Teams/'+name+'.txt', 'w', encoding=\"utf-8\") as f: # save the text for each character in the folder\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save raw text in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fb50e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_raw_team_text = {}\n",
    "\n",
    "team_names = df_teams[\"Name\"]\n",
    "\n",
    "for name in team_names:\n",
    "    name = name.replace(\"/\", \"%\")\n",
    "    with open('Teams/'+name+'.txt', 'r',encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        name = name.replace(\"%\",\"/\")\n",
    "        dict_raw_team_text[name] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting all characters within each teams   <a name=\"Extract_characters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(text, name, df):\n",
    "    \n",
    "    links_all = {}\n",
    "    \n",
    "    #founders\n",
    "    founders = []\n",
    "    founders_text = re.search(r'\\|founder (.*?)\\n', text)\n",
    "    if founders_text:\n",
    "        founders_text = founders_text.group(1)\n",
    "        founders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        founders = re.findall(founders_names, founders_text)\n",
    "        founders = [re.sub(r'\\/.*',\"\",member) for member in founders]\n",
    "        founders = [re.sub(r'.*\\|',\"\",member) for member in founders]\n",
    "    \n",
    "    #leaders\n",
    "    leaders = []\n",
    "    leaders_text = re.search(r'\\|leader (.*?)\\n', text)\n",
    "    if leaders_text:\n",
    "        leaders_text = leaders_text.group(1)\n",
    "        leaders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        leaders = re.findall(leaders_names, leaders_text)\n",
    "        leaders = [re.sub(r'\\/.*',\"\",member) for member in leaders]\n",
    "        leaders = [re.sub(r'.*\\|',\"\",member) for member in leaders]\n",
    "    \n",
    "    #former leaders\n",
    "    formleaders = []\n",
    "    formerleaders_text = re.search(r'\\|formerleaders (.*?)\\n', text)\n",
    "    if formerleaders_text:\n",
    "        formerleaders_text = formerleaders_text.group(1)\n",
    "        formerleaders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        formleaders = re.findall(formerleaders_names, formerleaders_text)\n",
    "        formleaders = [re.sub(r'\\/.*',\"\",member) for member in formleaders]\n",
    "        formleaders = [re.sub(r'.*\\|',\"\",member) for member in formleaders]\n",
    "    \n",
    "    \n",
    "    #members\n",
    "    members = []\n",
    "    members_text = re.search(r'\\|members (.*?)\\n', text)\n",
    "    if members_text:\n",
    "        members_text = members_text.group(1)\n",
    "        members_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        members = re.findall(members_names, members_text)\n",
    "        members = [re.sub(r'\\/.*',\"\",member) for member in members]\n",
    "        members = [re.sub(r'.*\\|',\"\",member) for member in members]\n",
    "    \n",
    "    #former members\n",
    "    formermembers = []\n",
    "    formermembers_text = re.search(r'\\|formermembers (.*?)\\n', text)\n",
    "    if formermembers_text:\n",
    "        formermembers_text = formermembers_text.group(1)\n",
    "        formermembers_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        formermembers = re.findall(formermembers_names, formermembers_text)\n",
    "        formermembers = [re.sub(r'\\/.*',\"\",member) for member in formermembers]\n",
    "        formermembers = [re.sub(r'.*\\|',\"\",member) for member in formermembers]\n",
    "        \n",
    "                                   \n",
    "    links_all = {\"Founders\": founders, \"Leaders\": leaders, \"Former leaders\": formleaders, \n",
    "                       \"Members\": members, \"Former members\": formermembers}\n",
    "    \n",
    "    links_org =[]\n",
    "    links_org.append(founders)\n",
    "    links_org.append(leaders)\n",
    "    links_org.append(formleaders)\n",
    "    links_org.append(members)\n",
    "    links_org.append(formermembers)\n",
    "    links_org = np.unique(links_org)\n",
    "    links_org = [item for sublist in links_org for item in sublist]\n",
    "    \n",
    "    return links_all, links_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links(dictionary):\n",
    "    links_role = {}\n",
    "    links_all = {}\n",
    "    for keys, values in dictionary.items():\n",
    "        link_role, link_org = get_links(values, keys, df_characters)\n",
    "        links_role[keys] = link_role\n",
    "        links_all[keys] = link_org\n",
    "    return links_role, links_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "team_roles, team_all = get_all_links(teams_raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering teams with more than one name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all teams with Categories or numbers in name\n",
    "remove = []\n",
    "for team in df_team.Name:\n",
    "    if (\"Category\" in team) or (team.isdigit())  :\n",
    "        df_team = df_team[df_team[\"Name\"] != team]\n",
    "        remove.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify teams with several names\n",
    "remove = [x for x in df_team['Name'] if (\"/\" in x) or (\"fiction\" in x)]\n",
    "remove.append(\"STRIKE Team: Delta\")\n",
    "remove.append(\"Avengers (Fiction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather all characters in same team if team have multiple names\n",
    "team_all_new = team_all.copy()\n",
    "for keys, values in team_all.items():\n",
    "    if keys in remove:\n",
    "        if keys == 'Avengers (Fiction)' or keys == 'STRIKE Team: Delta':\n",
    "            input_key = re.sub(r'\\s.*',\"\",keys)\n",
    "        else:\n",
    "            input_key = re.sub(r'\\/.*',\"\",keys)\n",
    "        if input_key in team_all.keys(): #check if org name without / is in dict\n",
    "            for name in values: \n",
    "                if name not in team_all_new[input_key]: #check if name is already in organisation\n",
    "                    team_all_new[input_key].append(name)\n",
    "            team_all_new.pop(keys) #remove old key\n",
    "        else:\n",
    "            team_all_new[input_key] = team_all_new.pop(keys)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather all characters roles in same team if team have multiple names\n",
    "team_roles_new = team_roles.copy()\n",
    "for keys, values in team_roles.items():\n",
    "    if keys in remove:\n",
    "        \n",
    "        if keys == 'Avengers (Fiction)' or keys == 'STRIKE Team: Delta':\n",
    "            input_key = re.sub(r'\\s.*',\"\",keys)\n",
    "        \n",
    "        else:\n",
    "            input_key = re.sub(r'\\/.*',\"\",keys)\n",
    "\n",
    "        if input_key in team_roles.keys(): #check if org name without / is in dict \n",
    "            for name in team_roles[keys][\"Founders\"]: \n",
    "                if name not in team_roles_new[input_key][\"Founders\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Founders\"].append(name)\n",
    "            \n",
    "            for name in team_roles[keys][\"Leaders\"]: \n",
    "                if name not in team_roles_new[input_key][\"Leaders\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Leaders\"].append(name)\n",
    "                    \n",
    "            for name in team_roles[keys][\"Former leaders\"]: \n",
    "                if name not in team_roles_new[input_key][\"Former leaders\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Former leaders\"].append(name)\n",
    "                    \n",
    "            for name in team_roles[keys][\"Members\"]: \n",
    "                if name not in team_roles_new[input_key][\"Members\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Members\"].append(name)\n",
    "                    \n",
    "            for name in team_roles[keys][\"Former members\"]: \n",
    "                if name not in team_roles_new[input_key][\"Former members\"]: #check if name is already in organisation\n",
    "                    team_roles_new[input_key][\"Former members\"].append(name)\n",
    "              \n",
    "            team_roles_new.pop(keys) #remove old key\n",
    "        else:\n",
    "            team_roles_new[input_key] = team_roles_new.pop(keys)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for graph visualisation  <a name=\"dict_for_team_viz\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with characters as keys and team as values\n",
    "dict_team_character = {}\n",
    "for name in df_characters[\"name\"]:\n",
    "    orgs = []\n",
    "    for keys, values in team_all_new.items():\n",
    "        if name in values:\n",
    "            orgs.append(keys)\n",
    "    dict_team_character[name] = orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with character and links to other characters within same team\n",
    "dict_team_org = {}\n",
    "for keys, values in dict_team_character.items():\n",
    "    characters = []\n",
    "    if values:\n",
    "        for org in values:\n",
    "            for names in team_all_new[org]: \n",
    "                if names != keys: #ensure that we do not create a link to the character itself\n",
    "                    characters.append(names)\n",
    "    dict_team_org[keys] = characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with teams and links to other teams if they share characters\n",
    "dict_links_team_name = {}\n",
    "for keys, values in team_all_new.items():\n",
    "    teams = []\n",
    "    count = 0\n",
    "    for i in range(len(team_all_new.keys())):\n",
    "        try:\n",
    "            next_key = list(team_all_new)[list(team_all_new).index(keys) + (i+1)]\n",
    "            for names in values:\n",
    "                if names in team_all_new[next_key]:\n",
    "                    teams.append(next_key)\n",
    "        except (ValueError, IndexError):\n",
    "            count += 1\n",
    "                \n",
    "    dict_links_team_name[keys] = teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all teams with no links to other organisations\n",
    "team_links_removed = {k: v for k, v in dict_links_team_name.items() if v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing characters that are not part of an organisation\n",
    "team_removed = {k: v for k, v in team_all_new.items() if v}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving dictionaries as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"team_shared.pickle\", \"wb\")\n",
    "pickle.dump(team_links_removed, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"team_characters.pickle\", \"wb\")\n",
    "pickle.dump(team_removed, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph attributes  <a name=\"graph_attributes\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_character_team = {}\n",
    "\n",
    "for keys1, values1 in dict_team_character.items():\n",
    "    orgs = []\n",
    "    founder = []\n",
    "    leader = []\n",
    "    form_leader = []\n",
    "    member = []\n",
    "    form_member = []\n",
    "    col = []\n",
    "    for keys2, values2 in team_roles_new.items():\n",
    "\n",
    "\n",
    "        teams = values1\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Founders']: #extract founder\n",
    "            founder.append(keys2)\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Leaders']: #extract leader\n",
    "            leader.append(keys2)\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Former leaders']: #extract former leader\n",
    "            form_leader.append(keys2)\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Members']: #extract member\n",
    "            member.append(keys2)\n",
    "\n",
    "        if keys1 in team_roles_new[keys2]['Former members']: #extract former member\n",
    "            form_member.append(keys2)\n",
    "\n",
    "\n",
    "        col = \"purple\"\n",
    "\n",
    "        attributes_character_team[keys1] = {\"Name\": keys1, \"Team(s)\": teams, \"Founder\": founder, \"Leader\": leader,\n",
    "                                    \"Former leader\": form_leader, \"Member\":member, \"Former member\":form_member,\n",
    "                                    \"Color\": col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def team_att(dictionary):\n",
    "    attributes_team = {}\n",
    "    \n",
    "    from random import randint\n",
    "    colors = []\n",
    "    n = len(dictionary)\n",
    "    for i in range(n):\n",
    "        \n",
    "        colors.append('#%06X' % randint(0, 0xFFFFFF))\n",
    "    n=0\n",
    "    for keys, values in dictionary.items(): \n",
    "        attributes_team[keys] = {\"Name\": keys , \"color\": str(colors[n]), \"shape\": \"diamond\"}\n",
    "        n = n+1\n",
    "    return attributes_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#number of times each organisation is mentioned in another orginasation\n",
    "links_no_team = team_links_removed.copy()\n",
    "for keys, values in team_links_removed.items():\n",
    "    counts = Counter(values)\n",
    "    links_no_team[keys] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"links_no_team.pickle\", \"wb\")\n",
    "pickle.dump(links_no_team, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_att(G):\n",
    "    '''\n",
    "    Function that returns edge attributes\n",
    "    '''\n",
    "    edge_att ={}\n",
    "    for u,v,_ in list(G.edges(data = True)):\n",
    "        \n",
    "        no_links = links_no[u][v]\n",
    "        \n",
    "        edge_att[(u,v)]={'value': no_links, 'title': 'No. of shared characters:' + str(no_links)}\n",
    "    return edge_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the characters within the teams have different aliases for the same character, all aliases are converted to their original hero name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_characters(dictionary):\n",
    "    removes =[]\n",
    "    for keys, values in dictionary.items():\n",
    "    \n",
    "        #Loki\n",
    "        lokis = ['Loki Variants','Classic Loki','Kid Loki','Boastful Loki','President Loki']\n",
    "        values = ['Loki' if i in lokis else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Thor\n",
    "        thors = ['Bruce Banner','Thor Odinson']\n",
    "        values = ['Thor' if i in thors else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Iron Man\n",
    "        IronMans = ['Tony Stark']\n",
    "        values = ['Iron Man' if i in IronMans else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Captain America\n",
    "        CA = [\"Sam Wilson\"]\n",
    "        values = ['Captain America' if i in CA else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "                \n",
    "        #Black Widow\n",
    "        Black_widows = ['Natasha Romanoff']\n",
    "        values = ['Black Widow' if i in Black_widows else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Hawkeye\n",
    "        Hawkeyes = ['Clint Barton']\n",
    "        values = ['Hawkeye' if i in Hawkeyes else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #War Machine\n",
    "        WarMachines = ['James Rhodes']\n",
    "        values = ['War Machine' if i in WarMachines else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Spyder Man\n",
    "        SpyderMans = ['Peter Parker']\n",
    "        values = ['Spider-Man' if i in SpyderMans else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Scarlet Witch\n",
    "        Wandas = ['Wanda Maximoff']\n",
    "        values = ['Scarlet Witch' if i in Wandas else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Quicksilver \n",
    "        Quicksilver = ['Pietro Maximoff']\n",
    "        values = ['Quicksilver' if i in Quicksilver else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Captain Marvel\n",
    "        CaptainMarvel = ['Carol Danvers']\n",
    "        values = ['Captain Marvel' if i in CaptainMarvel else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "        \n",
    "        #Ant-Man\n",
    "        AntMan = ['Scott Lang']\n",
    "        values = ['Ant-Man' if i in AntMan else i for i in values]\n",
    "        team_removed[keys] = np.unique(values)\n",
    "    \n",
    "    lists = [lokis,thors,IronMans,CA,Black_widows,Hawkeyes,WarMachines,SpyderMans,Wandas,Quicksilver,CaptainMarvel,AntMan]\n",
    "    for i in lists:\n",
    "        removes.append(i)\n",
    "    \n",
    "    removes = [item for sublist in removes for item in sublist]\n",
    "    \n",
    "    return dictionary, removes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the teams and roles to the original hero name that were assigned to the removed aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_attributes(attributes_character_team): \n",
    "\n",
    "    #update node attributes \n",
    "    attributes_character_team['Loki']['Team(s)'].append('Loki Variant Army')\n",
    "    attributes_character_team['Loki']['Former leader'].append('Loki Variant Army')\n",
    "    attributes_character_team['Captain America'] = {'Name':'Captain America', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[\"Avengers\"], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Scarlet Witch'] = {'Name':'Scarlet Witch', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Quicksilver'] = {'Name':'Quicksilver', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['War Machine'] = {'Name':'War Machine', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Sam Wilson'] = {'Name':'Sam Wilson', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Spider-Man'] = {'Name':'Spyder-Man', 'Team(s)':['Avengers'], 'Founder':[], 'Leader':[], 'Former leader':[], 'Member':[\"Avengers\"], 'Former member':[], 'Color':\"purple\"}\n",
    "    attributes_character_team['Captain Marvel'] = {'Name':'Captain Marvel', 'Team(s)':['Avengers','Sparrows'], 'Founder':[], 'Leader':[], 'Former leader':['Sparrows'], 'Member':[\"Avengers\"], 'Former member':['Sparrows'], 'Color':\"purple\"}\n",
    "    attributes_character_team['Ant-Man']['Member'].append('Avengers')\n",
    "    attributes_character_team['Ant-Man']['Team(s)'].append('Avengers')\n",
    "    \n",
    "    return attributes_character_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_removed,remove_from_att = convert_characters(team_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_character_all = update_attributes(attributes_character_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_character_team = attributes_character_all.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing aliases from the attributes used for the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'Classic Loki',\n",
       "  'Team(s)': ['Asgardian Royal Family'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': [],\n",
       "  'Member': [],\n",
       "  'Former member': ['Asgardian Royal Family'],\n",
       "  'Color': 'purple'},\n",
       " {'Name': 'Kid Loki',\n",
       "  'Team(s)': ['Asgardian Royal Family'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': [],\n",
       "  'Member': [],\n",
       "  'Former member': ['Asgardian Royal Family'],\n",
       "  'Color': 'purple'},\n",
       " {'Name': 'Boastful Loki',\n",
       "  'Team(s)': ['Asgardian Royal Family'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': [],\n",
       "  'Member': [],\n",
       "  'Former member': ['Asgardian Royal Family'],\n",
       "  'Color': 'purple'},\n",
       " {'Name': 'President Loki',\n",
       "  'Team(s)': ['Asgardian Royal Family', 'Loki Variant Army'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': ['Loki Variant Army'],\n",
       "  'Member': [],\n",
       "  'Former member': ['Asgardian Royal Family'],\n",
       "  'Color': 'purple'},\n",
       " {'Name': 'Sam Wilson',\n",
       "  'Team(s)': ['Avengers'],\n",
       "  'Founder': [],\n",
       "  'Leader': [],\n",
       "  'Former leader': [],\n",
       "  'Member': ['Avengers'],\n",
       "  'Former member': [],\n",
       "  'Color': 'purple'}]"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[attributes_character_team.pop(key) for key in remove_from_att if key in attributes_character_team.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_team = team_att(team_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organisation network <a name=\"organisation_network\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping text for each orginsation <a name=\"org_scraping\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://marvelcinematicuniverse.fandom.com/api.php?\"\n",
    "action = \"action=query\"\n",
    "content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "dataformat =\"format=json\"\n",
    "\n",
    "\n",
    "# list of character names - replacing the space with _ such that one can locate the right title\n",
    "organisations_names = df_organisation[\"Name\"]\n",
    "\n",
    "# Looping over every characters name using the same API logic and rexex as above\n",
    "for name in organisations_names:\n",
    "    if name == \"Duncan + Dotter Design\":\n",
    "        name = \"Duncan_%2B_Dotter_Design\"\n",
    "    \n",
    "    if name == \"M&R Credit Union\":\n",
    "        name = \"M%26R_Credit_Union\"\n",
    "    \n",
    "    name = name.replace(\" & \", \"_%26_\")\n",
    "\n",
    "    title = \"titles=\"+name\n",
    "    link = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\n",
    "    \n",
    "    wikiresponse = requests.get(link)\n",
    "    wikitext = wikiresponse.text\n",
    "    wikijson = json.loads(wikitext)\n",
    "\n",
    "    page_id = list(wikijson[\"query\"][\"pages\"].keys())[0] # The page id for each character\n",
    "    name = name.replace(\"/\", \"%\")\n",
    "    \n",
    "    if len(wikijson[\"query\"][\"pages\"][page_id]['revisions']) > 1:\n",
    "        print(\"Revisions has more than one entry\")\n",
    "    else:\n",
    "        text = wikijson[\"query\"][\"pages\"][page_id]['revisions'][0]['slots']['main']['*']\n",
    "        with open('Organisations/'+name+'.txt', 'w', encoding=\"utf-8\") as f: # save the text for each character in the folder\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save raw text in a dicctionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_raw_org_text = {}\n",
    "\n",
    "organisations_names = df_organisation[\"Name\"]\n",
    "\n",
    "for name in organisations_names:\n",
    "    if name == \"Duncan + Dotter Design\":\n",
    "        name = \"Duncan_%2B_Dotter_Design\"\n",
    "    if name == \"M&R Credit Union\":\n",
    "        name = \"M%26R_Credit_Union\"\n",
    "    name = name.replace(\" & \", \"_%26_\")\n",
    "    name = name.replace(\"/\", \"%\")\n",
    "    with open('Organisations/'+name+'.txt', 'r',encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        name = name.replace(\"Duncan_%2B_Dotter_Design\", \"Duncan + Dotter Design\")\n",
    "        name = name.replace(\"M%26R_Credit_Union\", \"M&R Credit Union\")\n",
    "        name = name.replace(\"%\",\"/\")\n",
    "        name = name.replace(\"_%26_\", \" & \")\n",
    "        dict_raw_org_text[name] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting all characters within each organisation <a name=\"org_extract_characters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(text, name, df):\n",
    "    \n",
    "    pattern_link = r'\\[\\[(.*?)\\]\\]'\n",
    "    \n",
    "    liste = []\n",
    "    links = re.findall(pattern_link, text)\n",
    "    \n",
    "    for l in links:\n",
    "        if (l in df[\"name\"].values) & (l != name):\n",
    "            liste.append(l)\n",
    "    \n",
    "    return list(np.unique(liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(text, name, df):\n",
    "    \n",
    "    links_all = {}\n",
    "    \n",
    "    #founders\n",
    "    founders = []\n",
    "    founders_text = re.search(r'\\|founder (.*?)\\n', text)\n",
    "    if founders_text:\n",
    "        founders_text = founders_text.group(1)\n",
    "        founders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        founders = re.findall(founders_names, founders_text)\n",
    "        founders = [re.sub(r'\\/.*',\"\",member) for member in founders]\n",
    "        founders = [re.sub(r'.*\\|',\"\",member) for member in founders]\n",
    "    \n",
    "    #leaders\n",
    "    leaders = []\n",
    "    leaders_text = re.search(r'\\|leader (.*?)\\n', text)\n",
    "    if leaders_text:\n",
    "        leaders_text = leaders_text.group(1)\n",
    "        leaders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        leaders = re.findall(leaders_names, leaders_text)\n",
    "        leaders = [re.sub(r'\\/.*',\"\",member) for member in leaders]\n",
    "        leaders = [re.sub(r'.*\\|',\"\",member) for member in leaders]\n",
    "    \n",
    "    #former leaders\n",
    "    formleaders = []\n",
    "    formerleaders_text = re.search(r'\\|formerleaders (.*?)\\n', text)\n",
    "    if formerleaders_text:\n",
    "        formerleaders_text = formerleaders_text.group(1)\n",
    "        formerleaders_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        formleaders = re.findall(formerleaders_names, formerleaders_text)\n",
    "        formleaders = [re.sub(r'\\/.*',\"\",member) for member in formleaders]\n",
    "        formleaders = [re.sub(r'.*\\|',\"\",member) for member in formleaders]\n",
    "    \n",
    "    \n",
    "    #members\n",
    "    members = []\n",
    "    members_text = re.search(r'\\|members (.*?)\\n', text)\n",
    "    if members_text:\n",
    "        members_text = members_text.group(1)\n",
    "        members_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        members = re.findall(members_names, members_text)\n",
    "        members = [re.sub(r'\\/.*',\"\",member) for member in members]\n",
    "        members = [re.sub(r'.*\\|',\"\",member) for member in members]\n",
    "    \n",
    "    #former members\n",
    "    formermembers = []\n",
    "    formermembers_text = re.search(r'\\|formermembers (.*?)\\n', text)\n",
    "    if formermembers_text:\n",
    "        formermembers_text = formermembers_text.group(1)\n",
    "        formermembers_names = r'\\[\\[(.*?)\\]\\]'\n",
    "        formermembers = re.findall(formermembers_names, formermembers_text)\n",
    "        formermembers = [re.sub(r'\\/.*',\"\",member) for member in formermembers]\n",
    "        formermembers = [re.sub(r'.*\\|',\"\",member) for member in formermembers]\n",
    "        \n",
    "                                   \n",
    "    links_all = {\"Founders\": founders, \"Leaders\": leaders, \"Former leaders\": formleaders, \n",
    "                       \"Members\": members, \"Former members\": formermembers}\n",
    "    \n",
    "    links_org =[]\n",
    "    links_org.append(founders)\n",
    "    links_org.append(leaders)\n",
    "    links_org.append(formleaders)\n",
    "    links_org.append(members)\n",
    "    links_org.append(formermembers)\n",
    "    links_org = np.unique(links_org)\n",
    "    links_org = [item for sublist in links_org for item in sublist]\n",
    "    \n",
    "    return links_all, links_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links(dictionary):\n",
    "    links_role = {}\n",
    "    links_all = {}\n",
    "    for keys, values in dictionary.items():\n",
    "        link_role, link_org = get_links(values, keys, df_characters)\n",
    "        links_role[keys] = link_role\n",
    "        links_all[keys] = link_org\n",
    "    return links_role, links_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malen\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "org_roles, org_all = get_all_links(dict_raw_org_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing organisation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove organisation if name contains \"Category\" as these are repititions or if they contain digits as the represent newspapers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = []\n",
    "for org in df_organisation.Name:\n",
    "    if (\"Category\" in org) or (org.isdigit())  :\n",
    "        df_organisation = df_organisation[df_organisation[\"Name\"] != org]\n",
    "        remove.append(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_organisation = df_organisation.iloc[3: , :]\n",
    "df_organisation = df_organisation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering organisations and characters if organisations have several names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idenitifying organisations with several names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = [x for x in df_organisation['Name'] if \"/\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_organisation = df_organisation.loc[df_organisation[\"Name\"]!= \"Avengers/Avengers Assassinated\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather all characters roles in same organisation if organisation have multiple names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather all characters roles in same organisation if organisation have multiple names\n",
    "org_roles_new = org_roles.copy()\n",
    "for keys, values in org_roles.items():\n",
    "    if keys in remove:\n",
    "        \n",
    "        input_key = re.sub(r'\\/.*',\"\",keys)\n",
    "\n",
    "        if input_key in org_roles.keys(): #check if org name without / is in dict \n",
    "            for name in org_roles[keys][\"Founders\"]: \n",
    "                if name not in org_roles_new[input_key][\"Founders\"]: #check if name is already in organisation\n",
    "                    org_roles_new[input_key][\"Founders\"].append(name)\n",
    "            \n",
    "            for name in org_roles[keys][\"Leaders\"]: \n",
    "                if name not in org_roles_new[input_key][\"Leaders\"]: #check if name is already in organisation\n",
    "                    org_roles_new[input_key][\"Leaders\"].append(name)\n",
    "                    \n",
    "            for name in org_roles[keys][\"Former leaders\"]: \n",
    "                if name not in org_roles_new[input_key][\"Former leaders\"]: #check if name is already in organisation\n",
    "                    org_roles_new[input_key][\"Former leaders\"].append(name)\n",
    "                    \n",
    "            for name in org_roles[keys][\"Members\"]: \n",
    "                if name not in org_roles_new[input_key][\"Members\"]: #check if name is already in organisation\n",
    "                    org_roles_new[input_key][\"Members\"].append(name)\n",
    "                    \n",
    "            for name in org_roles[keys][\"Former members\"]: \n",
    "                if name not in org_roles_new[input_key][\"Former members\"]: #check if name is already in organisation\n",
    "                    org_roles_new[input_key][\"Former members\"].append(name)\n",
    "              \n",
    "            org_roles_new.pop(keys) #remove old key\n",
    "        else:\n",
    "            org_roles_new[input_key] = org_roles_new.pop(keys)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather all characters in same organisation if organisation have multiple names\n",
    "org_all_new = org_all.copy()\n",
    "for keys, values in org_all.items():\n",
    "    if keys in remove:\n",
    "        input_key = re.sub(r'\\/.*',\"\",keys)\n",
    "        if input_key in org_all.keys(): #check if org name without / is in dict\n",
    "            for name in values: \n",
    "                if name not in org_all_new[input_key]: #check if name is already in organisation\n",
    "                    org_all_new[input_key].append(name)\n",
    "            org_all_new.pop(keys) #remove old key\n",
    "        else:\n",
    "            org_all_new[input_key] = org_all_new.pop(keys)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries used for graph representations  <a name=\"org_dict_for_viz\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with characters as keys and organisations as values\n",
    "dict_org_character = {}\n",
    "for name in df_characters[\"name\"]:\n",
    "    orgs = []\n",
    "    for keys, values in org_all_new.items():\n",
    "        if name in values:\n",
    "            orgs.append(keys)\n",
    "    dict_org_character[name] = orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary with organisations and links to other organisation if they share characters\n",
    "dict_links_org_name = {}\n",
    "for keys, values in org_all_new.items():\n",
    "    orgs = []\n",
    "    count = 0\n",
    "    for i in range(len(org_all_new.keys())):\n",
    "        try:\n",
    "            next_key = list(org_all_new)[list(org_all_new).index(keys) + (i+1)]\n",
    "            for names in values:\n",
    "                if names in org_all_new[next_key]:\n",
    "                    orgs.append(next_key)\n",
    "        except (ValueError, IndexError):\n",
    "            count += 1\n",
    "                \n",
    "    dict_links_org_name[keys] = orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all organisation with no links to other organisations\n",
    "org_links_removed = {k: v for k, v in dict_links_org_name.items() if v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing characters that are not part of an organisation\n",
    "org_removed = {k: v for k, v in org_all_new.items() if v}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving dictionaries as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"org_shared.pickle\", \"wb\")\n",
    "pickle.dump(org_links_removed, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"org_characters.pickle\", \"wb\")\n",
    "pickle.dump(org_removed, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph attributes <a name=\"org_graph_attr\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_character_org = {}\n",
    "\n",
    "for keys1, values1 in dict_org_character.items():\n",
    "    orgs = []\n",
    "    founder = []\n",
    "    leader = []\n",
    "    form_leader = []\n",
    "    member = []\n",
    "    form_member = []\n",
    "    col = []\n",
    "    for keys2, values2 in org_roles_new.items():\n",
    "\n",
    "\n",
    "        orgs = values1\n",
    "\n",
    "        if keys1 in org_roles_new[keys2]['Founders']: #extract founder\n",
    "            founder.append(keys2)\n",
    "\n",
    "        if keys1 in org_roles_new[keys2]['Leaders']: #extract leader\n",
    "            leader.append(keys2)\n",
    "\n",
    "        if keys1 in org_roles_new[keys2]['Former leaders']: #extract former leader\n",
    "            form_leader.append(keys2)\n",
    "\n",
    "        if keys1 in org_roles_new[keys2]['Members']: #extract member\n",
    "            member.append(keys2)\n",
    "\n",
    "        if keys1 in org_roles_new[keys2]['Former members']: #extract former member\n",
    "            form_member.append(keys2)\n",
    "\n",
    "\n",
    "        col = \"purple\"\n",
    "\n",
    "        attributes_character_org[keys1] = {\"Name\": keys1, \"Organisation(s)\": orgs, \"Founder\": founder, \"Leader\": leader,\n",
    "                                    \"Former leader\": form_leader, \"Member\":member, \"Former member\":form_member,\n",
    "                                    \"Color\": col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"attributes_character_org.pickle\", \"wb\")\n",
    "pickle.dump(attributes_character_org, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#number of times each organisation is mentioned in another orginasation\n",
    "links_no = org_links_removed.copy()\n",
    "for keys, values in org_links_removed.items():\n",
    "    counts = Counter(values)\n",
    "    links_no[keys] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_to_store = open(\"links_no.pickle\", \"wb\")\n",
    "pickle.dump(links_no, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
